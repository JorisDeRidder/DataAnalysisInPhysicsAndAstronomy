{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "from pymc import gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytensor\n",
    "import pytensor.tensor as pt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font',   size=16)          # controls default text sizes\n",
    "plt.rc('axes',   titlesize=20)     # fontsize of the axes title\n",
    "plt.rc('axes',   labelsize=20)     # fontsize of the x and y labels\n",
    "plt.rc('xtick',  labelsize=20)     # fontsize of the tick labels\n",
    "plt.rc('ytick',  labelsize=20)     # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=18)      # legend fontsize\n",
    "plt.rc('figure', titlesize=18)     # fontsize of the figure title"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"Scipy: \", sp.__version__)\n",
    "print(\"Pandas: \", pd.__version__)\n",
    "print(\"pymc: \", pm.__version__)\n",
    "print(\"pytensor: \", pytensor.__version__)\n",
    "print(\"arviz: \", az.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing posterior functions from a GP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1354)\n",
    "x = np.linspace(0.1,10,20)\n",
    "y = np.sin(x) / x + rng.normal(0, 0.1, len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x,y,s=20)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1                                             # This is a 1-dimensional problem\n",
    "X = x.reshape((len(x),1))                           # marginal_likelihood expects a column vector, not a row vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    lam = pm.Gamma('lambda', 2, 0.5)\n",
    "    covarianceFunction = gp.cov.ExpQuad(dim, ls=lam)\n",
    "    myGP = gp.Marginal(cov_func = covarianceFunction)\n",
    "    sigma = pm.HalfCauchy('sigma', 1)\n",
    "    likelihood = myGP.marginal_likelihood('y', X=X, y=y, sigma=sigma)\n",
    "    idata = pm.sample(500, chains=4, cores=2, return_inferencedata=True)                  # inference data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = az.plot_trace(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, hdi_prob=0.95, round_to=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the Maximum A Posteriori values for the scale length $\\lambda$ of our covariance function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = pm.find_MAP(model=myModel)\n",
    "print(\"MAP scale length: \", MAP['lambda'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean posterior $E[f(x^*)]$ manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.linspace(0.01, 15, 200).reshape((200,1))             # Column vector instead of row vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(x)\n",
    "cov = gp.cov.ExpQuad(1, MAP['lambda'])\n",
    "K = cov(X)\n",
    "Kstar = cov(X, Xnew)\n",
    "Knoise = K + MAP['sigma'] * np.eye(N)\n",
    "\n",
    "L = np.linalg.cholesky(Knoise.eval())\n",
    "A = np.linalg.solve(L.T, np.linalg.solve(L, y))\n",
    "meanPosterior = Kstar.T.eval() @ A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the Gaussian process for a few functions which we will also plot. By default `pm.sample_posterior_predictive()` samples as many functions as there are points in the trace which is too much. We therefore only select every 40th point of the trace and continue with this. This will leave us with about 25 posterior predictve sampled functions `f`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with myModel:\n",
    "    f = myGP.conditional('f', Xnew)\n",
    "    thinned = idata.sel(draw=slice(None, None, 40))                                                      # Only for every 40th point. To speed up, and to make the plot more clear.\n",
    "    idata.extend(pm.sample_posterior_predictive(thinned, var_names=['f']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`idata.posterior_predictive.f` now contains function `f` evaluations for each of the 200 `Xnew` points. However it is stored in a somewhat impractical way: as a `(4, 25, 200)` array. 4 because we used 4 chains, 25 is the number of sampled functions for each of our chain, and 200 the number of x-values in which we evaluate `f`. In the following we merge all the 4 chains together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nchains, Nsamples, Nxvalues = idata.posterior_predictive.f.shape\n",
    "post_pred_dist = np.array(idata.posterior_predictive.f).transpose().reshape(Nxvalues, Nchains*Nsamples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot each of the 4*25 = 100 posterior predictive functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "plt.plot(Xnew, meanPosterior, c='red', linewidth=2)\n",
    "ax.scatter(x,y,s=30,c=\"C0\")\n",
    "plt.plot(Xnew, post_pred_dist, c='grey', alpha=0.1)\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(13534)\n",
    "\n",
    "x = np.linspace(0, 1, 300)\n",
    "ytrue = np.sin(2*np.pi*x) + np.sin(7*np.pi*x)\n",
    "y = ytrue + rng.normal(0.0, 0.3, len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(9,5))\n",
    "ax.scatter(x,y,s=30,c=\"C0\")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put the GP fitting into a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitGP(x, y, lamda, xnew):\n",
    "    \n",
    "    dim = 1                                      # This is a 1-dimensional problem\n",
    "    X = x.reshape((len(x),1))                    # marginal_likelihood expects a column vector, not a row vector\n",
    "    Xnew = xnew.reshape((len(xnew),1))\n",
    "\n",
    "    # Fit the GP model\n",
    "    \n",
    "    with pm.Model() as myModel:\n",
    "        sigmaCovFunction = pm.HalfCauchy('sigma_cov', 5)\n",
    "        covarianceFunction = gp.cov.Constant(sigmaCovFunction) * gp.cov.ExpQuad(dim, ls=lamda)\n",
    "        myGP = gp.Marginal(cov_func = covarianceFunction)\n",
    "        sigmaNoise = pm.HalfCauchy('sigma', 1)\n",
    "        likelihood = myGP.marginal_likelihood('y', X=X, y=y, sigma=sigmaNoise)\n",
    "        idata = pm.sample(chains=3, cores=2, return_inferencedata=True)\n",
    "   \n",
    "    # Estimate the posterior predictive distribution\n",
    "    \n",
    "    with myModel:\n",
    "        f = myGP.conditional('f', Xnew)\n",
    "        thinned = idata.sel(draw=slice(None, None, 40))                                                      # Only for every 40th point. To speed up things.\n",
    "        idata.extend(pm.sample_posterior_predictive(thinned, var_names=['f']))\n",
    "    \n",
    "    return myModel, idata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‼️ Note: the `marginal_likelihood()` function does not accept Pandas vectors; it does accept NumPy arrays. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try $\\lambda = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.linspace(0,1,80)\n",
    "model, idata = fitGP(x, y, 1.0, Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(9,5))\n",
    "\n",
    "meanPosterior = np.array(idata.posterior_predictive.f.mean(axis=(0,1)))                # Average over all samples and chains\n",
    "\n",
    "plt.plot(Xnew, meanPosterior, c='red', linewidth=2)\n",
    "ax.scatter(x,y,s=10,c=\"C0\")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try $\\lambda = 0.001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, idata = fitGP(x, y, 0.001, Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(9,5))\n",
    "\n",
    "meanPosterior = np.array(idata.posterior_predictive.f.mean(axis=(0,1)))                # Average over all samples and chains\n",
    "\n",
    "plt.plot(Xnew, meanPosterior, c='red', linewidth=1)\n",
    "ax.scatter(x,y,s=10,c=\"C0\")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include $\\lambda$ in the probabilistic model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1                                       # This is a 1-dimensional problem\n",
    "X = x.reshape((len(x),1))                     # marginal_likelihood expects a column vector, not a row vector\n",
    "Xnew = np.linspace(0,1,80).reshape(80,1)\n",
    "\n",
    "with pm.Model() as myModel:\n",
    "     lamda = pm.Gamma('lambda', 2, 0.5)\n",
    "     sigmaCovFunction = pm.HalfCauchy('sigma_cov', 5)\n",
    "     covarianceFunction = gp.cov.Constant(sigmaCovFunction) * gp.cov.ExpQuad(dim, ls=lamda)\n",
    "     myGP = gp.Marginal(cov_func = covarianceFunction)\n",
    "     sigmaNoise = pm.HalfCauchy('sigma', 1)\n",
    "     likelihood = myGP.marginal_likelihood('y', X=X, y=y, sigma=sigmaNoise)\n",
    "\n",
    "     idata = pm.sample(chains=3, cores=2, return_inferencedata=True)\n",
    "       \n",
    "\n",
    "with myModel:\n",
    "     f = myGP.conditional('f', Xnew)\n",
    "     thinned = idata.sel(draw=slice(None, None, 40))        # Only for every 40th point. To speed up things.\n",
    "     idata.extend(pm.sample_posterior_predictive(thinned, var_names=['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(9,5))\n",
    "\n",
    "mean = np.array(idata.posterior_predictive.f.mean(axis=(0,1)))                # Average over all samples and chains\n",
    "std = np.array(idata.posterior_predictive.f.std(axis=(0,1), ddof=1)) \n",
    "\n",
    "ax.plot(Xnew, mean, c='red', linewidth=2)\n",
    "ax.fill_between(Xnew.flatten(), mean-3*std, mean+3*std, color=\"pink\", alpha=1)\n",
    "\n",
    "ax.scatter(x,y,s=10,c=\"C0\")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example: the Mauna Loa dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is strongly inspired by an example in the PyMC documentation pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/CO2_MaunaLoa_monthly.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data.head()\n",
    "t = data['year'].values\n",
    "y = data['co2'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataset shows why our planet risks to become uninhabitable if we do not act (very) fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.plot(data.year, data.co2, marker='o', markersize=3)\n",
    "ax.set_xlabel(\"year\")\n",
    "ax.set_ylabel(\"Monthly CO2 averages [ppm]\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model uses a sum of three GPs to capture the periodic trend, the long-term trend, and small/medium term irregularities. Cf the [PyMC documentation page](https://docs.pymc.io/api/gp/cov.html) on available covariance functions for a Gaussian Process. Note: depending on the dataset you use, the model can be rather slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    # The slowly varying long-term trend\n",
    "    \n",
    "    etaTrend      = pm.HalfCauchy(\"etaTrend\", beta=2, initval=2.0)\n",
    "    lambdaExpQuad = pm.Gamma(\"lambdaExpQuad\", alpha=4, beta=0.1)\n",
    "    covTrend      = etaTrend**2 * gp.cov.ExpQuad(1, lambdaExpQuad)\n",
    "    \n",
    "    myGPtrend = pm.gp.Marginal(cov_func=covTrend)\n",
    "\n",
    "    # Periodic component: PyMC3 has only one covariance function available to model periodic data\n",
    "    # The periodicity may not remain exact, so we multiply by a Matern52 function to take into account\n",
    "    # a decay of the exact periodic component. We put a long decay time, however, because we don't expect\n",
    "    # this to happen any soon.\n",
    "    \n",
    "    period         = pm.Normal(\"period\",          mu=1, sigma=0.05)\n",
    "    lambdaPeriodic = pm.Gamma(\"lambdaPeriodic\",   alpha=4, beta=3)\n",
    "    etaPeriodic    = pm.HalfCauchy(\"etaPeriodic\", beta=2, initval=1.0)\n",
    "    lambdaMatern52 = pm.Gamma(\"lambdaMatern52\",   alpha=10, beta=0.075)\n",
    "    covSeasonal    = etaPeriodic**2 * gp.cov.Periodic(1, period, lambdaPeriodic) * gp.cov.Matern52(1, lambdaMatern52)\n",
    "    \n",
    "    myGPseasonal = pm.gp.Marginal(cov_func=covSeasonal)\n",
    "    \n",
    "    # On top of all these perodicities and trends, there is also noise. It's unclear whether it's pure\n",
    "    # white noise, so we also add a Matern32 process to add noise on a somewhat longer time scale.\n",
    "    \n",
    "    etaNoise       = pm.HalfNormal(\"etaNoise\", sigma=0.5, initval=0.05)\n",
    "    lambdaMatern32 = pm.Gamma(\"lambdaNoise\", alpha=2, beta=4)\n",
    "    #sigma          = pm.HalfNormal(\"sigma\", sigma=0.25, initval=0.05)                                     # There is currently a bug (#6673) in gp that causes the following line to fail with gp.cov.WhiteNoise.\n",
    "    #covNoise       = etaNoise**2 * gp.cov.Matern32(1, lambdaMatern32) + gp.cov.WhiteNoise(sigma)\n",
    "    covNoise       = etaNoise**2 * gp.cov.Matern32(1, lambdaMatern32)\n",
    "\n",
    "    # The Gaussian process is a sum of these components\n",
    "    \n",
    "    myGP = myGPseasonal + myGPtrend\n",
    "\n",
    "    # The likelihood\n",
    "    \n",
    "    likelihood = myGP.marginal_likelihood(\"y\", X=t.reshape((len(t),1)), y=y, sigma=covNoise)\n",
    "\n",
    "    # Find the MAP values \n",
    "    \n",
    "    MAP = pm.find_MAP(include_transformed=True)\n",
    "\n",
    "    # Sample\n",
    "\n",
    "    idata = pm.sample(500, chains=2, cores=4, return_inferencedata=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the GP to predict the posterior mean and the posterior variance between the years 2015 and 2030."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process worker_chain_1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/site-packages/pymc/sampling/parallel.py\", line 122, in run\n",
      "    self._start_loop()\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/site-packages/pymc/sampling/parallel.py\", line 187, in _start_loop\n",
      "    self._msg_pipe.send((\"writing_done\", is_last, draw, tuning, stats))\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/multiprocessing/connection.py\", line 205, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/multiprocessing/connection.py\", line 367, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/site-packages/pymc/sampling/parallel.py\", line 194, in _run_process\n",
      "    _Process(*args).run()\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/site-packages/pymc/sampling/parallel.py\", line 129, in run\n",
      "    self._msg_pipe.send((\"error\", e))\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/multiprocessing/connection.py\", line 205, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/joris/opt/miniconda3/envs/course311/lib/python3.11/multiprocessing/connection.py\", line 367, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "tnew = np.linspace(2015, 2030, 15*12*2)[:,None]\n",
    "mu, var = myGP.predict(tnew, point=MAP, diag=True)\n",
    "sigma = np.sqrt(var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the mean, and the 1-sigma and 3-sigma intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "ax.scatter(data.year, data.co2, s=30)\n",
    "ax.plot(tnew, mu, c=\"red\")\n",
    "ax.fill_between(tnew.ravel(), mu-sigma, mu+sigma, color=\"red\", alpha=0.1)\n",
    "ax.fill_between(tnew.ravel(), mu-3*sigma, mu+3*sigma, color=\"red\", alpha=0.1)\n",
    "ax.set_xlabel(\"year\")\n",
    "ax.set_ylabel(\"Monthly CO2 averages [ppm]\")\n",
    "ax.set_xlim(2015, 2030)\n",
    "ax.set_ylim(390,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
