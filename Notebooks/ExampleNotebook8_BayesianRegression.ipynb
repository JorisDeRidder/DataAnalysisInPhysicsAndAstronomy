{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian regression using PyMC and STAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report any errors to Joris De Ridder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.11.0 | packaged by conda-forge | (main, Jan 14 2023, 12:25:12) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version: \", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:  1.24.3\n",
      "SciPy version:  1.10.1\n",
      "Pandas version:  1.5.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "print(\"NumPy version: \", np.__version__)\n",
    "print(\"SciPy version: \", sp.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statsmodels version:  0.13.5\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "print(\"Statsmodels version: \", sm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMC version:  5.3.0\n",
      "PyTensor version:  2.11.1\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import pytensor\n",
    "import pytensor.tensor as pt \n",
    "print(\"PyMC version: \", pm.__version__)\n",
    "print(\"PyTensor version: \", pytensor.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyStan version:  3.6.0\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "print(\"PyStan version: \", stan.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version:  3.7.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "print(\"Matplotlib version: \", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotly version:  5.14.1\n"
     ]
    }
   ],
   "source": [
    "import plotly\n",
    "print(\"Plotly version: \", plotly.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arviz version:  0.15.1\n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "print(\"Arviz version: \", az.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corner version:  2.2.2\n"
     ]
    }
   ],
   "source": [
    "import corner\n",
    "print(\"Corner version: \", corner.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmfit version:  1.2.1\n",
      "sympy version:  1.11.1\n",
      "sklearn version:  1.2.2\n"
     ]
    }
   ],
   "source": [
    "import lmfit\n",
    "import sympy\n",
    "import sklearn\n",
    "print(\"lmfit version: \", lmfit.__version__)\n",
    "print(\"sympy version: \", sympy.__version__)\n",
    "print(\"sklearn version: \", sklearn.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib font sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font',   size=15)          # controls default text sizes\n",
    "plt.rc('axes',   titlesize=15)     # fontsize of the axes title\n",
    "plt.rc('axes',   labelsize=15)     # fontsize of the x and y labels\n",
    "plt.rc('xtick',  labelsize=15)     # fontsize of the tick labels\n",
    "plt.rc('ytick',  labelsize=15)     # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=15)      # legend fontsize\n",
    "plt.rc('figure', titlesize=15)     # fontsize of the figure title"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links to documentation on the web"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [PyMC documentation](https://docs.pymc.io)\n",
    "* [PyMC examples](https://www.pymc.io/projects/examples/en/latest/gallery.html)\n",
    "* [Stan documentation](https://mc-stan.org/docs/2_26/stan-users-guide/index.html).\n",
    "* [Stan example models](https://github.com/stan-dev/example-models)\n",
    "* [A brief guide to Stan's warnings](https://mc-stan.org/misc/warnings.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Basic linear regression [PyMC]](#Basic-linear-regression-with-PyMC)\n",
    "* [Linear regression using a design matrix [PyMC]](#Linear-regression-using-a-design-matrix-with-PyMC)\n",
    "* [Basic linear regression [Stan]](#Basic-linear-regression-with-Stan)\n",
    "* [Robust regression using a Student's T-distribution [PyMC]](#Robust-regression-using-a-StudentT-likelihood-with-PyMC)\n",
    "* [Robust regression using the Hogg et al. approach [PyMC]](#Robust-regression-using-the-Hogg-approach-with-PyMC)\n",
    "* [Robust regression using the Hogg et al. approach [Stan]](#Robust-regression-using-the-Hogg-approach-with-Stan)\n",
    "* [Piecewise linear regression [PyMC]](#Piecewise-linear-regression-with-PyMC)\n",
    "* [Piecewise linear regression [Stan]](#Piecewise-linear-regression-with-Stan)\n",
    "* [Uncertainties in y and x [Stan]](#Uncertainties-in-y-and-x-with-Stan)\n",
    "* [Uncertainties in y and x [PyMC]](#Uncertainties-in-y-and-x-with-PyMC)\n",
    "* [Fitting a distribution to a dataset [PyMC]](#Modeling-a-distribution-for-a-dataset-with-PyMC)\n",
    "* [Binomial logistic regression [Stan]](#Fitting-a-binomial-logistic-model-with-Stan)\n",
    "* [Binomial logistic regression [PyMC]](#Fitting-a-logistic-model-with-PyMC)\n",
    "* [Multinomial logistic regression [Stan]](#A-multinomial-logistic-model-with-Stan)\n",
    "* [Multinomial logistic regression [PyMC]](#A-multinomial-logistic-model-with-PyMC)\n",
    "* [Modeling a fraction with Beta [Stan]](#Modeling-a-fraction-with-the-Beta-distribution-with-Stan)\n",
    "* [Modeling counts with Poisson [PyMC]](#Modeling-counts-with-Poisson-with-PyMC)\n",
    "* [Modeling counts with Poisson [Stan]](#Modeling-counts-with-Poisson-with-Stan)\n",
    "* [Modeling counts with Negative Binomial [PyMC]](#Modeling-counts-with-Negative-Binomial-with-PyMC)\n",
    "* [Modeling counts with Negative Binomial [Stan]](#Modeling-counts-with-Negative-Binomial-with-Stan)\n",
    "* [Zero-truncated Poisson model [Stan]](#A-zero-truncated-Poisson-model-with-Stan)\n",
    "* [Zero-truncated Poisson model [PyMC]](#A-zero-truncated-Poisson-model-with-PyMC)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic linear regression with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(14)\n",
    "\n",
    "N = 50\n",
    "theta0 = 1\n",
    "theta1 = 2\n",
    "sigma = 0.3\n",
    "\n",
    "x = np.linspace(0, 1, N)\n",
    "y = theta0 + theta1 * x + rng.normal(0.0, sigma, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.scatter(x, y, s=20)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Bayesian model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Bayesian model:\n",
    "\n",
    "$\\mu = \\theta_0+\\theta_1 x$\n",
    "\n",
    "$\\theta_1 = \\tan(\\alpha)$\n",
    "\n",
    "$\\alpha \\sim {\\rm Uniform}(-\\pi/2, +\\pi/2)$ \n",
    "\n",
    "$\\theta_0 \\sim {\\rm Normal}(0, 20)$\n",
    "\n",
    "$\\sigma \\sim {\\rm HalfCauchy}(\\beta=3)$\n",
    "\n",
    "$y \\sim {\\rm Normal}(\\mu, \\sigma)$\n",
    "\n",
    "\n",
    "See the [PyMC documentation](https://docs.pymc.io/api/distributions/continuous.html#pymc3.distributions.continuous.HalfCauchy) on the definition of the HalfCauchy distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    \n",
    "    xobs = pm.MutableData(\"xobs\", x)\n",
    "    yobs = pm.MutableData(\"yobs\", y)\n",
    "    \n",
    "    sigma     = pm.HalfCauchy(\"sigma\", beta=3)\n",
    "    intercept = pm.Normal(\"intercept\", 0, sigma=20)\n",
    "    angle     = pm.Uniform(\"angle\", -np.pi/2, +np.pi/2)\n",
    "    slope     = pm.Deterministic('slope', np.tan(angle))\n",
    "    \n",
    "    likelihood = pm.Normal(\"y\", mu=intercept + slope * xobs, sigma=sigma, observed=yobs)\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['intercept', 'slope', 'sigma'], hdi_prob=0.95, round_to=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean posterior values of the fit parameters can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = pm.summary(trace, var_names=['intercept', 'slope', 'sigma'])['mean']\n",
    "meanIntercept = posteriorMean.intercept\n",
    "meanSlope = posteriorMean.slope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the behavior of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope', 'sigma'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-correlation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = az.plot_autocorr(trace, var_names=(\"intercept\", \"slope\"), max_lag=50, combined=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One and two-dimensional projections of the posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3, figsize=(8,8))                                       # 3 because we're showing 3 params\n",
    "fig = corner.corner(trace, fig=fig, var_names=['intercept', 'slope', 'sigma'],\n",
    "                           quantiles=[0.16, 0.5, 0.84],\n",
    "                           show_titles=True, \n",
    "                           title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPlot = az.plot_posterior(trace, var_names=['intercept', 'slope'], point_estimate='mean', hdi_prob=0.95, textsize=15, round_to=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arviz allows to make a 2D contour plot of posterior samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8)) \n",
    "kde_kwargs = {'contour_kwargs': {'levels': 10}}\n",
    "az.plot_pair(trace, ax=ax, var_names=['intercept', 'slope'], kind='kde', kde_kwargs=kde_kwargs);\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5, alpha=0.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the posterior model and the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first stack all the samples of all chains in one large stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = trace.posterior.stack(draws=(\"chain\", \"draw\"))\n",
    "slope = stacked.slope.values\n",
    "intercept = stacked.intercept.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = pm.find_MAP(model=myModel)\n",
    "MAPintercept = MAP['intercept']\n",
    "MAPslope = MAP['slope']\n",
    "print(\"MAP value intercept: \", MAPintercept)\n",
    "print(\"MAP value slope: \", MAPslope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6)) \n",
    "ax.scatter(x,y, s=10)\n",
    "\n",
    "M = len(slope)//1000\n",
    "for n in range(0, len(slope), M):\n",
    "    ax.plot(x, intercept[n] + slope[n]*x, c=\"gray\", linewidth=1, alpha=0.03)\n",
    "\n",
    "#ax.plot(x, meanIntercept + meanSlope * x, c=\"red\", linewidth=1.5)\n",
    "ax.plot(x, MAPintercept + MAPslope * x, c=\"red\", linewidth=1.5)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior predictive distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to compute the posterior predictive distribution for a set of new x-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nnew = 30\n",
    "xnew = np.linspace(0, 1, Nnew)                        # Our set of new x-values \n",
    "with myModel:                                         # Use the same model as before \n",
    "   pm.set_data(\n",
    "   {\n",
    "      \"xobs\": xnew,                                   # Reset the x-values\n",
    "      \"yobs\": np.zeros_like(xnew)                     # Not needed, but must be same size as xobs\n",
    "   })\n",
    "\n",
    "   postPred = pm.sample_posterior_predictive(trace.posterior, return_inferencedata=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the Bayesian result is not a point estimate, but a distribution. For example the ynew distribution for xnew[0] and xnew[10] is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "az.plot_kde(np.array(postPred.posterior_predictive['y'][:,:,0]).flatten(), ax=ax)\n",
    "az.plot_kde(np.array(postPred.posterior_predictive['y'][:,:,10]).flatten(), ax=ax)\n",
    "ax.set_xlabel(\"ynew\")\n",
    "ax.set_ylabel(\"density\")\n",
    "ax.set_title(f\"Posterior predictive distribution for xnew = {xnew[0]} and xnew = {xnew[10]}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 95% high-density probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanPostPred = postPred.posterior_predictive['y'].mean(axis=(0,1))                        # Average over chains and samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x,y, s=10)\n",
    "ax.plot(xnew, meanPostPred, c=\"red\", linewidth=1.5)\n",
    "az.plot_hdi(xnew, postPred.posterior_predictive['y'], hdi_prob=0.95, color=\"lightsteelblue\", fill_kwargs={'alpha': 0.3}, ax=ax)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim(0,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare with a 95% prediction interval obtained using least-squares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y' : y, 'x': x})\n",
    "N = len(y)\n",
    "K = 2\n",
    "olsFit = sm.OLS.from_formula(formula='y ~ x', data=df).fit()\n",
    "s2 = np.sum(olsFit.resid**2) / (N-K)                               # Estimated variance of the (homescedastic) noise\n",
    "covMatrix = olsFit.cov_params()                                    # Covariance matrix of the fit parameters\n",
    "designX = sm.add_constant(np.column_stack([xnew]))                 # Design matrix\n",
    "ynew = designX @ olsFit.params                                     # Estimated y-values given the xnew values.\n",
    "\n",
    "sigma_y = np.zeros_like(xnew)\n",
    "for n in range(len(xnew)):\n",
    "    xvec = [1, xnew[n]]\n",
    "    sigma_y[n] = np.sqrt(xvec @ covMatrix @ xvec + s2)             # Uncertainty on the predicted y-value\n",
    "   \n",
    "Tdistrib = sp.stats.t(N-K)                                         # Student's T-distribution\n",
    "tMultiplier = Tdistrib.ppf(1-0.05/2)                               # 95% prediction interval\n",
    "\n",
    "lowerPI = ynew - tMultiplier * sigma_y                             # PI stands for Prediction Interval\n",
    "upperPI = ynew + tMultiplier * sigma_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x,y, s=10)\n",
    "ax.plot(xnew, meanPostPred, c=\"red\", linewidth=1.5)\n",
    "az.plot_hdi(xnew, postPred.posterior_predictive['y'], hdi_prob=0.95, color=\"lightsteelblue\", fill_kwargs={'alpha': 0.3}, ax=ax)   # The Bayesian version\n",
    "ax.plot(xnew, lowerPI, c=\"purple\", linewidth=1, linestyle='--')                                                                   # The Frequentist versoin\n",
    "ax.plot(xnew, upperPI, c=\"purple\", linewidth=1, linestyle='--')\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using a design matrix with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A synthetic dataset using a simply polynomial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(14)\n",
    "\n",
    "N = 50\n",
    "theta0 = 1\n",
    "theta1 = -0.5\n",
    "theta2 = 0.05\n",
    "theta3 = 0.005\n",
    "sigma = 0.3\n",
    "\n",
    "x = np.sort(rng.uniform(0,10,N))\n",
    "y = theta0 + theta1 * x + theta2 * x**2 + theta3 * x**3 + rng.normal(0.0, sigma, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "ax.scatter(x, y, s=20)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyMC model using the matrix notation for our linear model with the design matrix $X$:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X_{n,m} = x_n^m$\n",
    "\n",
    "$\\mu = X\\cdot\\theta$\n",
    "\n",
    "$\\theta_i = {\\rm Normal}(0, 2)$\n",
    "\n",
    "$\\sigma \\sim {\\rm HalfCauchy}(\\beta=3)$\n",
    "\n",
    "$y \\sim {\\rm Normal}(\\mu, \\sigma)$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code can be pretty slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    \n",
    "    xobs = pm.MutableData(\"xobs\", x)\n",
    "    yobs = pm.MutableData(\"yobs\", y)\n",
    "    \n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=3)\n",
    "    theta = pm.Normal('theta', mu=0.0, sigma=2.0, size=4)                        # 3rd order polynomial implies 4 coefficients \n",
    "    X_ = [xobs**k for k in range(4)]\n",
    "    X = pt.stack(X_, axis=1)\n",
    "\n",
    "    likelihood = pm.Normal(\"y\", mu=pt.dot(X, theta), sigma=sigma, observed=yobs)\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True, target_accept=0.98)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always check the trace(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary it becomes obvious that not all coefficients are significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, hdi_prob=0.95, round_to=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of 1 coefficient can be extracted with, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)['mean']['theta[0]']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual for polynomial regression, the coefficients are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5, figsize=(8,8))                                       # 3 because we're showing 3 params\n",
    "fig = corner.corner(trace, fig=fig, quantiles=[0.16, 0.5, 0.84], show_titles=True, title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic linear regression with Stan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same dataset and the same Bayesian model as in the previous example with PyMC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(14)\n",
    "\n",
    "N = 50\n",
    "theta0 = 1\n",
    "theta1 = 2\n",
    "sigma = 0.3\n",
    "\n",
    "x = np.linspace(0, 1, N)\n",
    "y = theta0 + theta1 * x + rng.normal(0.0, sigma, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nnew = 30\n",
    "xnew = np.linspace(0, 1, Nnew)                        # x-values for the posterior prediction "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statements with `Nnew`, `xnew`, and `ynew` are only necessary if you want to do posterior predictive sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;\n",
    "  vector[N] x;\n",
    "  vector[N] y;\n",
    "  int<lower=1> Nnew;\n",
    "  vector[Nnew] xnew;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real intercept;\n",
    "  real<lower=-pi()/2, upper=+pi()/2> angle;\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "\n",
    "transformed parameters{ \n",
    "  real slope;\n",
    "  slope = tan(angle);\n",
    "}\n",
    "\n",
    "model {\n",
    "  intercept ~ normal(0, 20);\n",
    "  angle     ~ uniform(-pi()/2, +pi()/2);\n",
    "  sigma     ~ cauchy(0, 3.0);\n",
    "  y         ~ normal(intercept + slope * x, sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  real ynew[Nnew] = normal_rng(intercept + slope * xnew, sigma);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = {\"N\": N, \"x\": x, \"y\": y, 'Nnew': Nnew, 'xnew': xnew}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=135)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following initialValues are usually redundant, as Stan is pretty good in choosing reasonable values on its own. I include the example, just in case you do want to experiment with initial values. Note that you need to give initial values for each chain (hence 4 dictionary in the list below), and the initial values need to be within the lower/upper constraints you specified in the model above. It's usually **not** a great idea to initialize the sampler with the MAP estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialValues = [{'intercept': 1, 'angle':np.pi/2.1}, {\"intercept\": 2, 'angle': np.pi/2.1}, \n",
    "                 {'intercept': 1, 'angle':np.pi/2.3}, {\"intercept\": 1.5, 'angle': np.pi/2.5}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=3000, num_warmup=1000, init=initialValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['intercept', 'slope', 'sigma'], round_to=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot with the data, the median of the posterior, and the 2.5% and 97.5% quantiles of the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.quantile(trace['ynew'], 0.5, axis=1)\n",
    "lowerQuantile = np.quantile(trace['ynew'], 0.025, axis=1)\n",
    "upperQuantile = np.quantile(trace['ynew'], 0.975, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6)) \n",
    "ax.scatter(x,y, s=10)\n",
    "ax.plot(xnew, median, c=\"red\", linewidth=1.5)\n",
    "ax.fill_between(xnew, lowerQuantile, upperQuantile, color=\"lightblue\", alpha=0.2)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust regression using a StudentT likelihood with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a synthetic dataset with outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(82)\n",
    "N = 30\n",
    "x = np.linspace(0, 20, N)\n",
    "theta0 = 5\n",
    "theta1 = 1\n",
    "theta2 = 0.0001\n",
    "mu = theta0 + theta1 * x + theta2 * (x-5)**2     # noiseless\n",
    "sigma = 1.0                                      # Stdev of the noise\n",
    "y = mu + rng.normal(0, sigma, N)                 # with noise\n",
    "y[[0, 2, 7]] += 9                                # 3 outliers\n",
    "y[[19,21,23,25,28]] -= 9                         # 5 more outliers\n",
    "data = pd.DataFrame({'y': y, 'x': x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x, y, s=20)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The non-robust Bayesian model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mu = \\theta_0+\\theta_1 x$\n",
    "\n",
    "$\\theta_1 = \\tan(\\alpha)$\n",
    "\n",
    "$\\alpha \\sim {\\rm Uniform}(-\\pi/2, +\\pi/2)$ \n",
    "\n",
    "$\\theta_0 \\sim {\\rm Normal}(0, 20)$\n",
    "\n",
    "$\\sigma \\sim {\\rm HalfCauchy}(\\beta=3)$\n",
    "\n",
    "$y \\sim {\\rm Normal}(\\mu, \\sigma)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    \n",
    "    xobs      = pm.Data(\"xobs\", x)\n",
    "    yobs      = pm.Data(\"yobs\", y)\n",
    "    sigma     = pm.HalfCauchy(\"sigma\", beta=3)\n",
    "    intercept = pm.Normal(\"intercept\", 0, sigma=20)\n",
    "    angle     = pm.Uniform(\"angle\", -np.pi/2, +np.pi/2)\n",
    "    slope     = pm.Deterministic('slope', np.tan(angle))\n",
    "    \n",
    "    likelihood = pm.Normal(\"y\", mu=intercept + slope * xobs, sigma=sigma, observed=yobs)\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope', 'sigma'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the way too high value of $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = pm.summary(trace, var_names=['intercept', 'slope', 'sigma'])['mean']\n",
    "meanIntercept = posteriorMean.intercept\n",
    "meanSlope = posteriorMean.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x, y, s=20, label=\"data\")\n",
    "\n",
    "xvalues = np.linspace(0,20,50)\n",
    "yvalues = meanIntercept + meanSlope * xvalues\n",
    "ax.plot(xvalues, yvalues, c=\"red\", linewidth=2, label=\"non-robust posterior\")\n",
    "\n",
    "ytrue = theta0 + theta1 * xvalues + theta2 * (xvalues-5)**2\n",
    "ax.plot(xvalues, ytrue, c=\"purple\", linewidth=2, linestyle='--', alpha=0.5, label=\"true relation\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more robust Bayesian model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Student's T-distribution instead of a Gaussian distribution for the likelihood:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mu = \\theta_0+\\theta_1 x$\n",
    "\n",
    "$\\theta_1 = \\tan(\\alpha)$\n",
    "\n",
    "$\\alpha \\sim {\\rm Uniform}(-\\pi/2, +\\pi/2)$ \n",
    "\n",
    "$\\theta_0 \\sim {\\rm Normal}(0, 20)$\n",
    "\n",
    "$\\sigma \\sim {\\rm HalfCauchy}(\\beta=3)$\n",
    "\n",
    "$y \\sim {\\rm T}(\\mu, \\sigma, \\nu=1)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the T-distribution with $\\nu=1$ is the Cauchy distribution which has very broad tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    \n",
    "    xobs      = pm.Data(\"xobs\", x)\n",
    "    yobs      = pm.Data(\"yobs\", y)\n",
    "    sigma     = pm.HalfCauchy(\"sigma\", beta=3)\n",
    "    intercept = pm.Normal(\"intercept\", 0, sigma=20)\n",
    "    angle     = pm.Uniform(\"angle\", -np.pi/2, +np.pi/2)\n",
    "    slope     = pm.Deterministic('slope', np.tan(angle))\n",
    "    \n",
    "    likelihood = pm.StudentT('y', nu=1, mu=intercept + slope * xobs, sigma=sigma, observed=yobs)\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope', 'sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = pm.summary(trace, var_names=['intercept', 'slope', 'sigma'])['mean']\n",
    "meanIntercept = posteriorMean.intercept\n",
    "meanSlope = posteriorMean.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x, y, s=20, label=\"data\")\n",
    "\n",
    "xvalues = np.linspace(0,20,50)\n",
    "yvalues = meanIntercept + meanSlope * xvalues\n",
    "ax.plot(xvalues, yvalues, c=\"red\", linewidth=2, label=\"Robust posterior\")\n",
    "\n",
    "ytrue = theta0 + theta1 * xvalues + theta2 * (xvalues-5)**2\n",
    "ax.plot(xvalues, ytrue, c=\"purple\", linewidth=2, linestyle='--', alpha=0.5, label=\"true relation\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can try different values for the parameter $\\nu$ of the T-distribution and do a sensitivity analysis. Alternatively, one can include a hyperprior distribution for $\\nu$. Gelman et al. (2003) suggests that one might try\n",
    "\n",
    "$$ \\nu^{-1} \\sim {\\rm Uniform}(0,1) $$\n",
    "\n",
    "This hyperprior distribution favors long-tailed likelihoods, with half of the prior probability falling between $T(\\nu=1)$ and $T(\\nu=2)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust regression using the Hogg approach with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same outlier dataset as in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(82)\n",
    "N = 30\n",
    "x = np.linspace(0, 20, N)\n",
    "theta0 = 5\n",
    "theta1 = 1\n",
    "theta2 = 0.0001\n",
    "mu = theta0 + theta1 * x + theta2 * (x-5)**2     # noiseless\n",
    "sigma = 1.0                                      # Stdev of the noise\n",
    "y = mu + rng.normal(0, sigma, N)                 # with noise\n",
    "y[[0, 2, 7]] += 9                                # 3 outliers\n",
    "y[[19,21,23,25,28]] -= 9                         # 5 more outliers\n",
    "data = pd.DataFrame({'y': y, 'x': x})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was inspired by the article of [Hogg et al. (2010)](https://arxiv.org/pdf/1008.4686v1.pdf). In particular, see their equation (17). This involves implementing a custom likelihood function using the `pm.DensityDist` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    \n",
    "    xobs = pm.Data(\"xobs\", x)\n",
    "    yobs = pm.Data(\"yobs\", y)\n",
    "    \n",
    "    sigmaInlier     = pm.HalfCauchy(\"sigma\", beta=3)\n",
    "    intercept       = pm.Normal(\"intercept\", 0, sigma=10)\n",
    "    angle           = pm.Uniform(\"angle\", -np.pi/2, +np.pi/2)\n",
    "    slope           = pm.Deterministic(\"slope\", np.tan(angle))   \n",
    "    muOutlier       = pm.Uniform(\"muOutlier\", -100, +100, initval=0)\n",
    "    logSigmaOutlier = pm.Uniform(\"logSigmaOutlier\", -5, 5, initval=2)\n",
    "    probOutlier     = pm.Uniform(\"probOutlier\", 0.0, 1.0, initval=0.1) \n",
    "    \n",
    "    def logLikelihood(y, x, sigmaInlier, intercept, angle, slope, muOutlier, logSigmaOutlier, probOutlier):\n",
    "        sigmaOutlier = pt.sqrt(pt.exp(logSigmaOutlier)**2 + sigmaInlier**2) \n",
    "        muInlier = intercept + slope * x\n",
    "        LikeInlier = 1./(sigmaInlier * np.sqrt(2*np.pi)) * pt.exp(-0.5 * (y - muInlier)**2 / sigmaInlier**2)\n",
    "        LikeOutlier = 1./(sigmaOutlier * np.sqrt(2*np.pi)) * pt.exp(-0.5 * (y - muOutlier)**2 / sigmaOutlier**2)\n",
    "        return pt.sum(pt.log((1 - probOutlier) * LikeInlier + probOutlier * LikeOutlier))\n",
    "\n",
    "    # Exact order of the arguments in logLiklihood should be copied in DensityDist. \n",
    "    likelihood = pm.DensityDist('likelihood', xobs, sigmaInlier, intercept, angle, slope, muOutlier, \n",
    "                                logSigmaOutlier, probOutlier, logp=logLikelihood, observed=yobs)\n",
    "\n",
    "    trace = pm.sample(4000, chains=4, cores=2, return_inferencedata=True, tune=2000, target_accept=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I needed to increase the acceptance probability to 0.95. PyMC will adapt the step size such that the average acceptance probability across the trajectories is close to `target_accept`. So, higher values for `target_accept` lead to smaller step sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = pm.summary(trace, var_names=['intercept', 'slope'])['mean']\n",
    "meanIntercept = posteriorMean.intercept\n",
    "meanSlope = posteriorMean.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x, y, s=20, label=\"data\")\n",
    "\n",
    "xvalues = np.linspace(0,20,50)\n",
    "yvalues = meanIntercept + meanSlope * xvalues\n",
    "ax.plot(xvalues, yvalues, c=\"red\", linewidth=2, label=\"Robust posterior\")\n",
    "\n",
    "ytrue = theta0 + theta1 * xvalues + theta2 * (xvalues-5)**2\n",
    "ax.plot(xvalues, ytrue, c=\"purple\", linewidth=2, linestyle='--', alpha=0.5, label=\"true relation\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust regression using the Hogg approach with Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(82)\n",
    "N = 30\n",
    "x = np.linspace(0, 20, N)\n",
    "theta0 = 5\n",
    "theta1 = 1\n",
    "theta2 = 0.0001\n",
    "mu = theta0 + theta1 * x + theta2 * (x-5)**2     # noiseless\n",
    "sigma = 1.0                                      # Stdev of the noise\n",
    "y = mu + rng.normal(0, sigma, N)                 # with noise\n",
    "y[[0, 2, 7]] += 9                                # 3 outliers\n",
    "y[[19,21,23,25,28]] -= 9                         # 5 more outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to make a custom likelihood is to define a function of the form\n",
    "\n",
    "`real xxxx_lpdf(real y, ...)`\n",
    "\n",
    "that contains the log-likelihood. However, when using the function, the `_lpdf` extenstion as well as the first argument `y` is ommitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "functions {\n",
    "\n",
    "  real likelihood_lpdf(real y, real x, real sigmaOutlier, real muOutlier, real sigmaInlier, real probOutlier, real intercept, real slope) \n",
    "  {\n",
    "     real muInlier;\n",
    "     real likeInlier;\n",
    "     real likeOutlier;\n",
    "     real logLike;\n",
    "     \n",
    "     muInlier = intercept + slope * x;\n",
    "     likeInlier  = 1./(sigmaInlier  * sqrt(2*pi())) * exp(-0.5 * square(y - muInlier) / square(sigmaInlier));\n",
    "     likeOutlier = 1./(sigmaOutlier * sqrt(2*pi())) * exp(-0.5 * square(y - muOutlier) / square(sigmaOutlier));  \n",
    "     logLike = log((1-probOutlier) * likeInlier + probOutlier * likeOutlier);\n",
    "     \n",
    "     return logLike; \n",
    "  }\n",
    "}\n",
    "\n",
    "data {\n",
    "  int<lower=1> N;\n",
    "  vector[N] x;\n",
    "  vector[N] y;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real intercept;\n",
    "  real<lower=-pi()/2, upper=+pi()/2> angle;\n",
    "  real<lower=0> sigmaInlier;\n",
    "  real logSigmaOutlier;\n",
    "  real muOutlier;\n",
    "  real<lower=0, upper=1> probOutlier;\n",
    "}\n",
    "\n",
    "transformed parameters{ \n",
    "  real slope;\n",
    "  slope = tan(angle);\n",
    "  real sigmaOutlier;\n",
    "  sigmaOutlier = sqrt(square(exp(logSigmaOutlier)) + square(sigmaInlier));\n",
    "}\n",
    "\n",
    "model {\n",
    "  intercept       ~ normal(0, 10);\n",
    "  angle           ~ uniform(-pi()/2, +pi()/2);\n",
    "  sigmaInlier     ~ cauchy(0, 2.0);\n",
    "  muOutlier       ~ uniform(-10, 50);\n",
    "  logSigmaOutlier ~ uniform(-0.1, 3);\n",
    "  probOutlier     ~ uniform(0,1);\n",
    "  \n",
    "  for (i in 1:N) {\n",
    "      y[i] ~ likelihood(x[i], sigmaOutlier, muOutlier, sigmaInlier, probOutlier, intercept, slope);\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = {\"N\": N, \"x\": x, \"y\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=3000, num_warmup=3000, delta=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceframe = trace.to_frame()\n",
    "print(\"Nr of divergences: \", traceframe['divergent__'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanIntercept = np.mean(trace['intercept'])\n",
    "meanSlope = np.mean(trace['slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6)) \n",
    "ax.scatter(x,y, s=10, label=\"data\")\n",
    "\n",
    "xvalues = np.linspace(0, 20, 30)\n",
    "yvalues = meanIntercept + meanSlope * xvalues;\n",
    "ax.plot(xvalues, yvalues, c=\"red\", linewidth=1.5, label=\"robust posterior\")\n",
    "\n",
    "ytrue = theta0 + theta1 * xvalues + theta2 * (xvalues-5)**2\n",
    "ax.plot(xvalues, ytrue, c=\"purple\", linewidth=2, linestyle='--', alpha=0.5, label=\"true relation\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piecewise linear regression with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(149)\n",
    "\n",
    "N = 50\n",
    "intercept1 = 1\n",
    "slope1 = 2\n",
    "intercept2 = 3.275\n",
    "slope2 = -1.5\n",
    "\n",
    "sigma = 0.15\n",
    "\n",
    "x = np.linspace(0, 2, N)\n",
    "\n",
    "piece1 = x < 0.65\n",
    "piece2 = x >= 0.65\n",
    "y = np.zeros(N)\n",
    "y[piece1] = intercept1 + slope1 * x[piece1] \n",
    "y[piece2] = intercept2 + slope2 * x[piece2] \n",
    "y += rng.normal(0.0, sigma, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x, y, s=10)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is not only to derive the intercepts and the slopes of the linear pieces, but also the location of the switch point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Bayesian model:\n",
    "\n",
    "$\\mu = \\theta_0+\\theta_1 x$   if $x <= x_0$\n",
    "\n",
    "$\\mu = \\theta_2+\\theta_3 x$   if $x > x_0$\n",
    "\n",
    "$\\theta_1 = \\tan(\\alpha_1)$\n",
    "\n",
    "$\\theta_3 = \\tan(\\alpha_2)$\n",
    "\n",
    "$\\alpha_1 \\sim {\\rm Uniform}(0, \\pi/2)$ \n",
    "\n",
    "$\\alpha_2 \\sim {\\rm Uniform}(-\\pi/2, 0)$ \n",
    "\n",
    "$\\theta_0 \\sim {\\rm Normal}(0, 5)$\n",
    "\n",
    "$\\theta_2 \\sim {\\rm Normal}(0, 5)$\n",
    "\n",
    "$\\sigma \\sim {\\rm HalfCauchy}(\\beta=3)$\n",
    "\n",
    "$y \\sim {\\rm Normal}(\\mu, \\sigma)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "\n",
    "    xobs        = pm.Data(\"xobs\", x, mutable=False)\n",
    "    yobs        = pm.Data(\"yobs\", y, mutable=False)\n",
    "    sigma       = pm.HalfCauchy(\"sigma\", beta=2)\n",
    "    intercept1  = pm.Normal(\"intercept1\", 0, sigma=5)\n",
    "    intercept2  = pm.Normal(\"intercept2\", 0, sigma=5)\n",
    "    angle1      = pm.Uniform(\"angle1\", 0, +np.pi/2)\n",
    "    angle2      = pm.Uniform(\"angle2\", -np.pi/2, 0)\n",
    "    slope1      = pm.Deterministic('slope1', np.tan(angle1))\n",
    "    slope2      = pm.Deterministic('slope2', np.tan(angle2))\n",
    "    switchpoint = pm.Normal('switchpoint', 0.6, 0.25) \n",
    "    intercept   = pm.math.switch(x <= switchpoint, intercept1, intercept2)\n",
    "    slope       = pm.math.switch(x <= switchpoint, slope1, slope2)\n",
    "    \n",
    "    likelihood = pm.Normal(\"y\", mu=intercept + slope * xobs, sigma=sigma, observed=yobs)\n",
    "\n",
    "    trace = pm.sample(2000, chains=4, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept1', 'slope1', 'intercept2', 'slope2', 'switchpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, round_to=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piecewise linear regression with Stan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same dataset and Bayesian model as in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \\\n",
    "\"\"\"\n",
    "data {\n",
    "  int<lower=1> N;      \n",
    "  vector[N] x;\n",
    "  vector[N] y;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real intercept1;\n",
    "  real intercept2;\n",
    "  real<lower=0, upper=pi()/2>  angle1;\n",
    "  real<lower=-pi()/2, upper=0> angle2;\n",
    "  real<lower=0> sigma;\n",
    "  real switchpoint;\n",
    "} \n",
    "\n",
    "transformed parameters{\n",
    "  real slope1;\n",
    "  real slope2;\n",
    "  \n",
    "  slope1 = tan(angle1);\n",
    "  slope2 = tan(angle2);\n",
    "}\n",
    "\n",
    "model {\n",
    "  intercept1  ~ normal(0, 5);\n",
    "  intercept2  ~ normal(0, 5);\n",
    "  angle1      ~ uniform(0, pi()/2);\n",
    "  angle2      ~ uniform(-pi()/2, 0);\n",
    "  switchpoint ~ uniform(0.45, 0.9);\n",
    "  sigma       ~ cauchy(0, 3.0);\n",
    "    \n",
    "  for (i in 1:N) {\n",
    "    if (x[i] < switchpoint) {\n",
    "       y[i] ~ normal(intercept1 + slope1 * x[i], sigma);\n",
    "    }\n",
    "    else {\n",
    "       y[i] ~ normal(intercept2 + slope2 * x[i], sigma);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = {\"N\": N, \"x\": x, \"y\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept1', 'slope1', 'intercept2', 'slope2', 'switchpoint', 'sigma'], divergences=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['intercept1', 'slope1', 'intercept2', 'slope2', 'switchpoint', 'sigma'], round_to=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainties in y and x with Stan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also the [Stan documentation on this topic](https://mc-stan.org/docs/2_19/stan-users-guide/bayesian-measurement-error-model.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/M_sigma.csv\"\n",
    "data = pd.read_csv(url, comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = {'N':len(data)}\n",
    "for name in ['xobs', 'xerr', 'yobs', 'yerr']:\n",
    "    myData[name] = data[name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "ax.errorbar(data['xobs'], data['yobs'], xerr=data['xerr'], yerr=data['yerr'], linestyle='', ms=15)\n",
    "ax.set_xlabel(r\"$\\ln(\\sigma/\\sigma_0)$\")\n",
    "ax.set_ylabel(r\"$\\ln(M_{\\bullet}/M_{\\odot})$\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will approximate the relation between $y_{\\rm true}$ and $x_{\\rm true}$ with a simple linear model, but we recognize that we're not very certain of this relation, and that the true relation may deviate from a linear one. We model this uncertainty with\n",
    "\n",
    "$ y_{\\rm true} = \\theta_0 + \\theta_1\\, x_{\\rm true} + \\mathcal{N}(0, \\zeta) $\n",
    "\n",
    "Since we don't have a clue how large $\\zeta$ may be, we take a broad half StudentT distribution:\n",
    "\n",
    "$ \\zeta \\sim {\\rm HalfStudentT}(\\nu=1, \\mu=0, \\sigma=4) $\n",
    "\n",
    "We have measurement errors on both $x$ and $y$ which we model with\n",
    "\n",
    "$ y_{\\rm obs} \\sim \\mathcal{N}(y_{\\rm true}, \\sigma_y) $\n",
    "\n",
    "$ x_{\\rm obs} \\sim \\mathcal{N}(x_{\\rm true}, \\sigma_x) $\n",
    "\n",
    "where we take $\\sigma_x = {\\rm xerr}$ and $\\sigma_y = {\\rm yerr}$, the observed uncertainties. For the prior on $x_{\\rm true}$ we take an extremely broad distribution:\n",
    "\n",
    "$ x_{\\rm true} \\sim \\mathcal{N}(0, 20) $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \\\n",
    "\"\"\"\n",
    "data {\n",
    "  int<lower=1> N;                                      // number of data points\n",
    "  vector[N] xobs;                                      // observed velocity dispersion\n",
    "  vector[N] xerr;                                      // uncertainty on observed velocity scatter\n",
    "  vector[N] yobs;                                      // observed black hole mass\n",
    "  vector[N] yerr;                                      // uncertainty on black hole mass\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real intercept;                                      \n",
    "  real slope;                                          \n",
    "  real<lower=0> zeta;                                  // scatter of ytrue around the linear relation\n",
    "  vector[N] xtrue;                                     // true but unknown velocity dispersion\n",
    "  vector[N] ytrue;                                     // true but unknown black hole mass \n",
    "}\n",
    "\n",
    "model {\n",
    "  intercept ~ normal(0, 100);\n",
    "  slope     ~ normal(0, 100);\n",
    "  zeta      ~ student_t(1, 0, 4);\n",
    "  xtrue     ~ normal(0, 20);                           // hyper-prior\n",
    "  xobs      ~ normal(xtrue, xerr);\n",
    "  ytrue     ~ normal(intercept + slope * xtrue, zeta);\n",
    "  yobs      ~ normal(ytrue, yerr);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=3, num_samples=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['intercept', 'slope', 'zeta'], round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanIntercept = np.mean(trace['intercept'])\n",
    "meanSlope = np.mean(trace['slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,12))\n",
    "\n",
    "ax.errorbar(data['xobs'], data['yobs'], xerr=data['xerr'], yerr=data['yerr'], linestyle='', ms=15)\n",
    "\n",
    "xvalues = np.linspace(-0.5, 0.4, 30)\n",
    "yvalues = meanIntercept + meanSlope * xvalues\n",
    "ax.plot(xvalues, yvalues, c=\"red\", linewidth=2, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel(r\"$\\ln(\\sigma/\\sigma_0)$\")\n",
    "ax.set_ylabel(r\"$\\ln(M_{\\rm BH}/M_{\\odot})$\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainties in y and x with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same dataset as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/M_sigma.csv\"\n",
    "data = pd.read_csv(url, comment='#')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "ax.errorbar(data['xobs'], data['yobs'], xerr=data['xerr'], yerr=data['yerr'], linestyle='', ms=15)\n",
    "ax.set_xlabel(r\"$\\ln(\\sigma/\\sigma_0)$\")\n",
    "ax.set_ylabel(r\"$\\ln(M_{\\bullet}/M_{\\odot})$\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we leave out the construction with $\\zeta$, and we assume that we know the exact relation between $x_{\\rm true}$ and $y_{\\rm true}$:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ y_{\\rm true} = \\theta_0 + \\theta_1\\, x_{\\rm true}  $\n",
    "\n",
    "As before we model the measurements with errors on both $x$ and $y$ with\n",
    "\n",
    "$ y_{\\rm obs} \\sim \\mathcal{N}(y_{\\rm true}, \\sigma_y) $\n",
    "\n",
    "$ x_{\\rm obs} \\sim \\mathcal{N}(x_{\\rm true}, \\sigma_x) $\n",
    "\n",
    "where we take $\\sigma_x = {\\rm xerr}$ and $\\sigma_y = {\\rm yerr}$, the observed uncertainties. For the prior on $x_{\\rm true}$ we take an extremely broad distribution:\n",
    "\n",
    "$ x_{\\rm true} \\sim \\mathcal{N}(0, 20) $.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that PyMC allows to have two observed quantities, which we will make use of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "  xobs = pm.Data('xobs', data['xobs'].values)\n",
    "  yobs = pm.Data('yobs', data['yobs'].values)\n",
    "\n",
    "  intercept = pm.Normal('intercept', 0, 20)\n",
    "  alpha = pm.Uniform('alpha', 0.0, np.pi/2)\n",
    "  slope = pm.Deterministic('slope', np.tan(alpha))\n",
    "  true_x = pm.Normal('true_x', 0.0, 20.0, shape=len(data))\n",
    "  likelihood_x = pm.Normal('x', true_x, data['xerr'].values, observed=xobs)\n",
    "  true_y = pm.Deterministic('true_y', intercept + slope * true_x)\n",
    "  likelihood_y = pm.Normal('y', true_y, data['yerr'].values, observed=yobs)\n",
    "\n",
    "  trace = pm.sample(4000, chains=4, cores=2, return_inferencedata=True, tune=2000, target_accept=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the posteriors for a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope', 'true_x'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the mean posterior value of the intercept and the slope to calculate the true y-values given a grid of true x-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = pm.summary(trace)['mean']\n",
    "meanIntercept = posteriorMean.intercept\n",
    "meanSlope = posteriorMean.slope\n",
    "true_x = np.linspace(-0.5, 0.4, 100)\n",
    "true_y = meanIntercept + meanSlope * true_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overplot the mean curve on top of the data. Note that the data points use the observed x-values, while the mean curve uses the true x-values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "ax.errorbar(data['xobs'], data['yobs'], xerr=data['xerr'], yerr=data['yerr'], linestyle='', ms=15)\n",
    "ax.plot(true_x, true_y, c=\"red\")\n",
    "ax.set_xlabel(r\"$\\ln(\\sigma/\\sigma_0)$\")\n",
    "ax.set_ylabel(r\"$\\ln(M_{\\bullet}/M_{\\odot})$\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling a distribution for a dataset with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/NGC6611.csv\"\n",
    "data = pd.read_csv(url, comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,7))\n",
    "ax.hist(data['Mass'].values, bins=20, density=True)\n",
    "ax.set_xlabel(r\"Mass $[M_{\\odot}]$\")\n",
    "ax.set_ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to fit a log-normal distribution:\n",
    "    \n",
    "$$f_X(x) = \\frac{1}{x\\sigma\\sqrt{2\\pi}} \\ \\exp\\left(-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2} \\right)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y \\sim $ log-Normal $(\\mu, \\sigma^2)$\n",
    "\n",
    "$\\mu \\sim {\\rm Normal}(0, 10)$\n",
    "\n",
    "$\\sigma^2 \\sim$ HalfNormal $(0, 10^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    \n",
    "    yobs = pm.Data(\"yobs\", data['Mass'].values)\n",
    "    \n",
    "    mu         = pm.Normal(\"mu\", mu=0, sigma=10)\n",
    "    sigma      = pm.HalfNormal(\"sigma\", sigma=100)\n",
    "    likelihood = pm.Lognormal(\"Mass\", mu=mu, sigma=sigma, observed=yobs)\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['mu', 'sigma'], hdi_prob=0.95, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))     \n",
    "fig = corner.corner(trace, fig=fig, var_names=['mu', 'sigma'],\n",
    "                           quantiles=[0.025, 0.5, 0.975],\n",
    "                           show_titles=True, \n",
    "                           title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mu$ and $\\sigma$ seem uncorrelated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aims to overplot the mean log-normal distribution over the observed density. SciPy has a bit of a deviating version of the log-normal distribution, so we need our customary function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logNormal(x, mu, sigma):\n",
    "    return np.exp(-(np.log(x) - mu)**2/2/sigma**2) / x / sigma / np.sqrt(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanValues = pm.summary(trace, var_names=['mu', 'sigma'], hdi_prob=0.95)['mean']\n",
    "muMean = meanValues.mu\n",
    "sigmaMean = meanValues.sigma\n",
    "\n",
    "lowerQuantiles = pm.summary(trace, var_names=['mu', 'sigma'], hdi_prob=0.95)['hdi_2.5%']\n",
    "muLower = lowerQuantiles.mu\n",
    "sigmaLower = lowerQuantiles.sigma\n",
    "\n",
    "upperQuantiles = pm.summary(trace, var_names=['mu', 'sigma'], hdi_prob=0.95)['hdi_97.5%']\n",
    "muUpper = upperQuantiles.mu\n",
    "sigmaUpper = upperQuantiles.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmaUpper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = np.linspace(0.01, 1.5, 100)\n",
    "yvaluesMean  = logNormal(xvalues, muMean, sigmaMean)\n",
    "yvaluesLower = logNormal(xvalues, muLower, sigmaLower)\n",
    "yvaluesUpper = logNormal(xvalues, muUpper, sigmaUpper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,7))\n",
    "ax.hist(data['Mass'].values, bins=20, density=True)\n",
    "\n",
    "ax.fill_between(xvalues, yvaluesLower, yvaluesUpper, color=\"pink\", alpha=0.9)\n",
    "ax.plot(xvalues, yvaluesMean, c=\"red\", linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel(r\"Mass $[M_{\\odot}]$\")\n",
    "ax.set_ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a binomial logistic model with Stan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/Red_spirals.csv\"\n",
    "data = pd.read_csv(url, comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "\n",
    "red = data['type'] == 1\n",
    "blue = data['type'] == 0\n",
    "ax.hist(data.loc[blue, 'fracdev'], bins=20, rwidth=0.9, label=\"Blue spiral galaxies\")\n",
    "ax.hist(data.loc[red, 'fracdev'], bins=20, facecolor=\"red\", edgecolor=\"red\", rwidth=0.9, label=\"Red spiral galaxies\")\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel(\"fracdev\")\n",
    "ax.set_ylabel(\"count\")\n",
    "ax.set_ylim(0, 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \\\n",
    "\"\"\"\n",
    "data {\n",
    "  int<lower=0> N;                   // Number of data points\n",
    "  int<lower=0> K;                   // Number of model parameters\n",
    "  matrix[N,K] X;                    // Design matrix, bulge size\n",
    "  int y[N];                         // Galaxy type: 0: blue, 1: red\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  vector[K] theta;                  // Model parameters\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  real intercept;                   // Separate quantities just to make the trace plots more clear\n",
    "  real slope;\n",
    "  \n",
    "  intercept = theta[1];\n",
    "  slope = theta[2];\n",
    "}\n",
    "\n",
    "model {\n",
    "  for (k in 1:K) {\n",
    "    theta[k] ~ normal(0,10);\n",
    "  }\n",
    "  \n",
    "  y ~ bernoulli_logit(X * theta);   // p_i = inverse-logit(X * theta)\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vander(data['fracdev'].values, 2, increasing=True)\n",
    "y = data['type']\n",
    "myData = {'N': X.shape[0], 'K': X.shape[1], 'X': X, 'y': y.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['intercept', 'slope'], hdi_prob=0.95, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanIntercept = np.mean(trace['intercept'])\n",
    "meanSlope = np.mean(trace['slope'])\n",
    "xvalues = np.linspace(0, 0.5, 100)\n",
    "yvalues = 1/(1+np.exp(-meanIntercept-meanSlope*xvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 0.5, 20)\n",
    "binCenters = (bins[1:] + bins[:-1])/2.\n",
    "\n",
    "allGalaxies, dummy = np.histogram(data['fracdev'], bins=bins)\n",
    "redGalaxies, dummy = np.histogram(data.loc[red, 'fracdev'], bins=bins) \n",
    "fraction = redGalaxies / allGalaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "\n",
    "ax.scatter(binCenters, fraction)\n",
    "ax.plot(xvalues, yvalues, color=\"red\", linewidth=2)\n",
    "ax.set_xlabel(\"fracdev\")\n",
    "ax.set_ylabel(r\"$p_{\\rm red}$\")\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a binomial logistic model with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same dataset as in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/Red_spirals.csv\"\n",
    "data = pd.read_csv(url, comment='#')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    xobs = pm.Data(\"xobs\", data['fracdev'].values)\n",
    "    yobs = pm.Data(\"yobs\", data['type'].values)\n",
    "    intercept = pm.Normal('intercept', mu=0, sigma=10)\n",
    "    slope     = pm.Normal('slope', mu=0, sigma=10)\n",
    "    probRed   = pm.Deterministic('probRed', pm.math.sigmoid(intercept + slope * xobs))\n",
    "    y         = pm.Bernoulli('y', p=probRed, observed=yobs)\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['intercept', 'slope'], hdi_prob=0.95, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8)) \n",
    "kde_kwargs = {'contour_kwargs': {'levels': 10}}\n",
    "az.plot_pair(trace, ax=ax, var_names=['intercept', 'slope'], kind='kde', kde_kwargs=kde_kwargs);\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5, alpha=0.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = pm.summary(trace, var_names=['intercept', 'slope'])['mean']\n",
    "meanIntercept = posteriorMean.intercept\n",
    "meanSlope = posteriorMean.slope\n",
    "xvalues = np.linspace(0, 0.5, 100)\n",
    "yvalues = 1/(1+np.exp(-meanIntercept-meanSlope*xvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = trace.posterior.stack(draws=(\"chain\", \"draw\"))\n",
    "slope = stacked.slope.values\n",
    "intercept = stacked.intercept.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed fraction of red spirals w.r.t. the total number of spiral galaxies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 0.5, 20)\n",
    "binCenters = (bins[1:] + bins[:-1])/2.\n",
    "\n",
    "red = data['type'] == 1\n",
    "allGalaxies, dummy = np.histogram(data['fracdev'], bins=bins)\n",
    "redGalaxies, dummy = np.histogram(data.loc[red, 'fracdev'], bins=bins) \n",
    "fraction = redGalaxies / allGalaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "\n",
    "ax.plot(xvalues, yvalues, c=\"red\", linewidth=2)\n",
    "\n",
    "M = len(slope)//1000\n",
    "for n in range(0, len(slope), M):\n",
    "    yvalues = 1/(1+np.exp(-intercept[n]-slope[n]*xvalues))\n",
    "    ax.plot(xvalues, yvalues, c=\"gray\", linewidth=1, alpha=0.02)\n",
    "\n",
    "ax.scatter(binCenters, fraction)\n",
    "\n",
    "ax.set_xlabel(\"fracdev\")\n",
    "ax.set_ylabel(r\"$p_{\\rm red}$\")\n",
    "ax.set_xlim(0,0.5)\n",
    "ax.set_ylim(0,0.35)\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A multinomial logistic model with Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/AtomiumAGB5.csv\"\n",
    "data = pd.read_csv(url, comment='#')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As covariate we will use the logarithm of the mass loss. For the classes we prefer the number 0,1,2 instead of 1,2,3 because several software libraries expect the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.log10(data['Mdot']).values\n",
    "meanx = np.mean(x)\n",
    "x = x - meanx                                             # Recentering the covariate\n",
    "y = data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "ax.scatter(x, y, c=\"black\",s=25)\n",
    "\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel(r\"$\\log_{10}(\\dot{M} \\ / \\ (M_{\\odot} \\ yr^{-1}))$ + 5.977\")\n",
    "\n",
    "ax.set_yticks([1,2,3])\n",
    "ax.set_yticklabels(['Class 1','Class 2','Class 3'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following Stan script we use the first class as a pivot, which means that we set its intercept and slope to zero. The entire script is unfortunately not so trivial and we refer to the [relevant Stan example page](https://mc-stan.org/docs/2_19/stan-users-guide/multi-logit-section.html) for a more in-depth explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \\\n",
    "\"\"\"\n",
    "data {\n",
    "    int<lower=2> J;                               // Nr of categories (classes) \n",
    "    int<lower=1> N;                               // Nr of observations\n",
    "    int<lower=1> K;                               // Nr of covariates\n",
    "    int<lower=1,upper=J> y[N];                    // Our categorical data\n",
    "    matrix[N,K] X;                                // Design matrix  \n",
    "}\n",
    "\n",
    "transformed data {\n",
    "    vector[K] zeros = rep_vector(0, K);\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    matrix[K, J-1] theta_raw;  \n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "    matrix[K, J] theta;\n",
    "    theta = append_col(zeros, theta_raw);\n",
    "}\n",
    "\n",
    "model {\n",
    "\n",
    "    matrix[N,J] Xtheta = X * theta;\n",
    "\n",
    "    to_vector(theta_raw) ~ normal(0, 20);\n",
    "    \n",
    "    for (n in 1:N) {\n",
    "        y[n] ~ categorical_logit(Xtheta[n]');\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(x)                                                                       # Nr of observations\n",
    "K = 2                                                                            # Nr of regression coefficients\n",
    "J = 3                                                                            # Nr of categories (classes)\n",
    "X = np.column_stack([np.ones_like(x), x])                                        # Design matrix\n",
    "myData = {'N': N, 'K': K, 'J': J, 'X': X, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=835)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bandwidth problem is caused by the fact that we set the intercept and slope for the 1st class to be exact zero. Hence it cannot compute the bandwidth of the kernel density estimate as it is a delta function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTheta = az.summary(trace)['mean']\n",
    "meanTheta = np.array([meanTheta['theta[{0}, {1}]'.format(k,j)] for k in range(K) for j in range(J)]).reshape(K,J)\n",
    "print(meanTheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = np.linspace(-1.6, 1.7, 200)\n",
    "Xdesign = np.column_stack([np.ones_like(xvalues), xvalues])\n",
    "expXtheta = np.exp(np.dot(Xdesign, meanTheta))\n",
    "P2 = expXtheta[:,1] / expXtheta.sum(axis=1)\n",
    "P3 = expXtheta[:,2] / expXtheta.sum(axis=1)\n",
    "P1 = 1-P2-P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "ax.set_xlabel(r'$\\log_{10}(\\dot{M} \\ / \\ (M_{\\odot} \\ yr^{-1}))$', fontsize=18)\n",
    "ax.set_ylabel('probability', fontsize=18)\n",
    "ax.yaxis.set_label_coords(-0.07, 0.16)\n",
    "\n",
    "ax.set_yticks([0,1,2,3,4])\n",
    "ax.set_yticklabels(['0','1','Class 1', 'Class 2', 'Class 3'])\n",
    "\n",
    "ax.plot(xvalues, P1, c=\"orange\")\n",
    "ax.plot(xvalues, P2, c=\"blue\")\n",
    "ax.plot(xvalues, P3, c=\"green\")\n",
    "ax.scatter(x, y+1, c=\"black\", s=25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison we do the same multinomial logistic regression using the `statsmodels` library. Also here we use P1 as a pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = sm.MNLogit(y, X)\n",
    "myFit = myModel.fit(method=\"powell\")\n",
    "print(myFit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expXbeta = np.exp(np.dot(Xdesign, myFit.params))\n",
    "P2 = expXbeta[:,0] / (1 + expXbeta.sum(axis=1))\n",
    "P3 = expXbeta[:,1] / (1 + expXbeta.sum(axis=1))\n",
    "P1 = 1-P2-P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "ax.set_xlabel(r'$\\log_{10}(\\dot{M} \\ / \\ (M_{\\odot} \\ yr^{-1}))$', fontsize=18)\n",
    "ax.set_ylabel('probability', fontsize=18)\n",
    "ax.yaxis.set_label_coords(-0.07, 0.16)\n",
    "\n",
    "ax.set_yticks([0,1,2,3,4])\n",
    "ax.set_yticklabels(['0','1','Class 1', 'Class 2', 'Class 3'])\n",
    "\n",
    "ax.plot(xvalues, P1, c=\"orange\")\n",
    "ax.plot(xvalues, P2, c=\"blue\")\n",
    "ax.plot(xvalues, P3, c=\"green\")\n",
    "ax.scatter(x, y+1, c=\"black\", s=25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A multinomial logistic model with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give an example on how to model a multinomial logistic model with PyMC we will first make a synthetic dataset, as this will be instructive on its own."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we have 3 classes, and a parameter 'x' that we can measure for each object we study. The probability that an object belongs to a particular class depends on its measured x-values. We aim to put forward a model for this dependence, and get posterior distributions for the model parameters.\n",
    "\n",
    "The reason why it's called a \"multinomial\" model is that we will model the data with a Multinomial probability distribution:\n",
    "\n",
    "$$ y_i \\sim {\\rm MultiNom}(N, \\ \\{p_1, p_2, \\cdots, p_k\\}) $$\n",
    "\n",
    "Here $k$ is the number of classes (in our example k=3), $p_j$ is the probability for an object to belong to class $j$. $N$ is called the number of \"trials\" or \"number of experiments\", when observations are done in batches. \n",
    "\n",
    "For example, for the case of 3 classes with probabilities $(p_1, p_2, p_3) = (0.2, 0.3, 0.5)$ and N=100 trials we can draw a Multinomial datapoint using Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 26 57]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(1984)\n",
    "y = rng.multinomial(100, [0.2, 0.3, 0.5])\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawn datapoint tells us that of the 100 trials, we got 17 objects of class 1, 26 objects of class 2, and 57 objects of class 3, which is pretty consistent with the probabilities we entered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multinomial distribution is a very general distribution that reduces to some other distributions for specific values of $N$ and $k$:\n",
    "* If $k=2$ and $N=1$, the multinomial distribution reduces to the _Bernoulli distribution_.\n",
    "* If $k=2$ and $N>1$, we obtain the _Binomial distribution_.\n",
    "* If $k>2$ and $N=1$, the multinomial distribution is also called the _Categorical distribution_. This is the case for the current example, as we observe just one star at a time.\n",
    "\n",
    "For example, for $k=3$ and $N=1$, we can draw 5 objects from the Multinomial distribution using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(9084)\n",
    "y = rng.multinomial(1, [0.2, 0.3, 0.5], size=5)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row $[1, 0, 0]$ means 1 object of class 1, and 0 objects of classes 2 and 3. That is, an object of class 1. So, the array above is equivalent with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class1', 'class3', 'class3', 'class2', 'class2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"class1\", \"class3\", \"class3\", \"class2\", \"class2\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or if we assign the numbers 0, 1, and 2 to respectively classes 1, 2, and 3, it's equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 2, 1, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,2,2,1,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latter form is usually how our observed dataset looks like."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use for each of the probabilities $p_j$ a linear model:\n",
    "\n",
    "$$ \\alpha_j + \\beta_j x. $$\n",
    "\n",
    "You might be tempted to use the logistic function to map this quantity into a probability $\\in [0,1]$:\n",
    "\n",
    "$$ p_j(x) = \\frac{1}{1+e^{-\\alpha_j - \\beta_j x}}  \\ \\ \\ \\ \\ \\ \\ \\ \\ (??)$$\n",
    "\n",
    "However, this does not take into account that the probabilities should add up to one: $p_1 + p_2 + p_3 = 1$. Instead, what is usually done is to model:\n",
    "\n",
    "$$ \\ln\\left(\\frac{p_2}{p_1}\\right) = \\alpha_2 + \\beta_2 x $$\n",
    "$$ \\ln\\left(\\frac{p_3}{p_1}\\right) = \\alpha_3 + \\beta_3 x $$\n",
    "\n",
    "and then use the fact that the probabilities add up to 1 to derive that:\n",
    "\n",
    "$$p_1(x) = \\frac{1}{1+e^{\\alpha_2 + \\beta_2 x}+e^{\\alpha_3+\\beta_3 x}} $$\n",
    "$$p_2(x) = \\frac{e^{\\alpha_2 + \\beta_2 x}}{1+e^{\\alpha_2 + \\beta_2 x}+e^{\\alpha_3+\\beta_3 x}} = p_1 \\ e^{\\alpha_2 + \\beta_2 x} $$\n",
    "$$p_3(x) = \\frac{e^{\\alpha_3+\\beta_3 x}}{1+e^{\\alpha_2 + \\beta_2 x}+e^{\\alpha_3+\\beta_3 x}} = p_1 \\ e^{\\alpha_3 + \\beta_3 x} $$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this knowledge we can generate our synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(1984)\n",
    "\n",
    "# Some arbitrarily chosen observed x-values\n",
    "\n",
    "xobs= np.sort(rng.uniform(-1.7, 1.5, size=50))\n",
    "\n",
    "# Generate the probabilities to belong to classes 1, 2, or 3\n",
    "\n",
    "exp2 = np.exp(0.0 + 4.0 * xobs) \n",
    "exp3 = np.exp(0.1 - 3* xobs) \n",
    "p1 = 1 / (1+exp2+exp3)\n",
    "p2 = exp2 * p1 \n",
    "p3 = exp3 * p1 \n",
    "p = np.array([p1,p2,p3]).transpose()                             # This is the format the numpy's multinomial function expects\n",
    "\n",
    "# Generate the data\n",
    "\n",
    "yobs = rng.multinomial(1, p)                                     # N=1 trial, but since we gave it 50 (p_1, p_2, p_3) triplets, it will generate 50 data points\n",
    "print(yobs[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform these observations that what a typical dataset looks like, I use the trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 1 0 1 2 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "observed_class = np.sum(yobs * [1, 2, 3], axis=1) - 1\n",
    "print(observed_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the numbers 0, 1, and 2, denote classes 1, 2, and 3. Why not use the numbers 1,2,3? See below: some library functions expect class numbers starting from 0. \n",
    "\n",
    "So we now have 50 objects, each with a measured 'x' value, drawn with a probability to belong to a certain class depending on that x-value.\n",
    "\n",
    "We can illustrate our dataset with the following figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('probability', fontsize=12)\n",
    "ax.yaxis.set_label_coords(-0.07, 0.16)\n",
    "\n",
    "ax.set_yticks([0,1,2,3,4])\n",
    "ax.set_yticklabels(['0','1','Class 1', 'Class 2', 'Class 3'])\n",
    "\n",
    "ax.plot(xobs, p1, c=\"orange\")\n",
    "ax.plot(xobs, p2, c=\"blue\")\n",
    "ax.plot(xobs, p3, c=\"green\")\n",
    "\n",
    "class1 = observed_class == 0\n",
    "ax.scatter(xobs[class1], observed_class[class1]+2, c=\"orange\", s=25)\n",
    "class2 = observed_class == 1\n",
    "ax.scatter(xobs[class2], observed_class[class2]+2, c=\"blue\", s=25)\n",
    "class3 = observed_class == 2\n",
    "ax.scatter(xobs[class3], observed_class[class3]+2, c=\"green\", s=25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability curves are the true (but unknown) ones that we used to generate this synthetic dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our PyMC model is quite easy, but you have to remember to use `pytensor` rather than `numpy` to derive the probabilities. As before, note the `transpose()` to reshape the array into the shape that `pm.Multinomial` expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [intercept2, slope2, intercept3, slope3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 3_000 draw iterations (4_000 + 12_000 draws total) took 5 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as myModel:\n",
    "\n",
    "    intercept2 = pm.Normal('intercept2', mu=0, sigma=10)\n",
    "    slope2     = pm.Normal('slope2',     mu=0, sigma=10)\n",
    "    intercept3 = pm.Normal('intercept3', mu=0, sigma=10)\n",
    "    slope3     = pm.Normal('slope3',     mu=0, sigma=10)\n",
    "\n",
    "    exp2 = pt.exp(intercept2+slope2*xobs)\n",
    "    exp3 = pt.exp(intercept3+slope3*xobs)\n",
    "    p1 = 1.0 / (1.0 + exp2+exp3)\n",
    "    p2 = exp2 * p1\n",
    "    p3 = exp3 * p1\n",
    "    p = pt.transpose([p1,p2,p3])\n",
    "    \n",
    "    likelihood = pm.Multinomial('y', n=1, p=p, observed=yobs)\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the posteriors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept2', 'slope2', 'intercept3', 'slope3'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that large uncertainties of our model parameters. This also shows in the posterior summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, hdi_prob=0.95, round_to=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the probability distributions on top of our dataset, we first extract the mean values for the intercepts and the slopes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = az.summary(trace)['mean']\n",
    "mean_intercept2 = posteriorMean.intercept2\n",
    "mean_slope2 = posteriorMean.slope2\n",
    "mean_intercept3 = posteriorMean.intercept3\n",
    "mean_slope3 = posteriorMean.slope3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to compute a mean distribution for each of the $p_j(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = np.linspace(-1.7, 1.5, 100)\n",
    "exp2 = np.exp(mean_intercept2 + mean_slope2 * xvalues)\n",
    "exp3 = np.exp(mean_intercept3 + mean_slope3 * xvalues)\n",
    "mean_p1 = 1.0 / (1.0 + exp2+exp3)\n",
    "mean_p2 = exp2 * mean_p1\n",
    "mean_p3 = exp3 * mean_p1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leading to the following figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('probability', fontsize=12)\n",
    "ax.yaxis.set_label_coords(-0.07, 0.16)\n",
    "\n",
    "ax.set_yticks([0,1,2,3,4])\n",
    "ax.set_yticklabels(['0','1','Class 1', 'Class 2', 'Class 3'])\n",
    "\n",
    "ax.plot(xvalues, mean_p1, c=\"orange\")\n",
    "ax.plot(xvalues, mean_p2, c=\"blue\")\n",
    "ax.plot(xvalues, mean_p3, c=\"green\")\n",
    "\n",
    "class1 = observed_class == 0\n",
    "ax.scatter(xobs[class1], observed_class[class1]+2, c=\"orange\", s=25)\n",
    "class2 = observed_class == 1\n",
    "ax.scatter(xobs[class2], observed_class[class2]+2, c=\"blue\", s=25)\n",
    "class3 = observed_class == 2\n",
    "ax.scatter(xobs[class3], observed_class[class3]+2, c=\"green\", s=25)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our `PyMC` model we used the observations `yobs`. For a synthetic dataset this particular form of data is easily derived, but for a real-life dataset we usually have something similar as `observed_class`. Isn't there an easier way so that we can just use the latter? There is indeed: by using the `pm.Categorical` distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "\n",
    "    intercept2 = pm.Normal('intercept2', mu=0, sigma=10)\n",
    "    slope2     = pm.Normal('slope2',     mu=0, sigma=10)\n",
    "    intercept3 = pm.Normal('intercept3', mu=0, sigma=10)\n",
    "    slope3     = pm.Normal('slope3',     mu=0, sigma=10)\n",
    "\n",
    "    exp2 = pt.exp(intercept2+slope2*xobs)\n",
    "    exp3 = pt.exp(intercept3+slope3*xobs)\n",
    "    p1 = 1.0 / (1.0 + exp2+exp3)\n",
    "    p2 = exp2 * p1\n",
    "    p3 = exp3 * p1\n",
    "    p = pt.transpose([p1,p2,p3])\n",
    "    \n",
    "    likelihood = pm.Categorical('y', p, observed=observed_class)\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leading to similar posteriors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept2', 'slope2', 'intercept3', 'slope3'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling a fraction with the Beta distribution with Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/f_gas.csv\"\n",
    "data = pd.read_csv(url, comment='#')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gasFraction = data['M_HI'].values / (data['M_HI'].values + data['M_STAR'].values)\n",
    "x = np.log10(data['M_STAR'].values)\n",
    "myData = {'N': len(x), 'x': x, 'y': gasFraction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "ax.scatter(np.log10(data['M_STAR']), gasFraction, s=10)\n",
    "ax.set_ylabel(\"Gas fraction\")\n",
    "ax.set_xlabel(r\"$\\log(M/M_{\\odot})$\")\n",
    "ax.set_ylim(0,1)\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nnew = 100\n",
    "xnew = np.linspace(6.5, 11.5, Nnew)\n",
    "myData['Nnew'] = Nnew\n",
    "myData['xnew'] = xnew"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \\\n",
    "\"\"\"\n",
    "data {\n",
    "    int<lower=0> N;                                   // Number of observations\n",
    "    real x[N];                                        // log10(mass)\n",
    "    real<lower=0, upper=1> y[N];                      // Gas fraction observations\n",
    "    int<lower=0> Nnew;                                // To compute posterior prediction interval\n",
    "    real xnew[Nnew]; \n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real intercept;\n",
    "    real slope;\n",
    "    real<lower=0> kappa;                              // Beta distribution parameter\n",
    "}\n",
    "\n",
    "model {\n",
    "    \n",
    "    vector[N] mu;                                     // Mean of the beta distribution\n",
    "    \n",
    "    for (n in 1:N) {\n",
    "        mu[n] = inv_logit(intercept + slope * x[n]);\n",
    "    }\n",
    "    \n",
    "    intercept ~ normal(0, 20);\n",
    "    slope ~ normal(0, 20);\n",
    "    kappa ~ student_t(4,0,1);\n",
    "    \n",
    "    y ~ beta_proportion(mu, kappa);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    \n",
    "    real aa[Nnew];\n",
    "    real bb[Nnew];\n",
    "    real eta[Nnew];\n",
    "    \n",
    "    for (n in 1:Nnew) {\n",
    "        eta[n] = inv_logit(intercept + slope * xnew[n]); \n",
    "        aa[n] = eta[n] * kappa;\n",
    "        bb[n] = (1-eta[n]) * kappa;\n",
    "    }\n",
    "    real ynew[Nnew] = beta_rng(aa, bb);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=13593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope', 'kappa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanIntercept = np.mean(trace['intercept'])\n",
    "meanSlope = np.mean(trace['slope'])\n",
    "xvalues = np.linspace(6.5, 11.5, 100)\n",
    "yvalues = 1/(1+np.exp(-meanIntercept-meanSlope*xvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.quantile(trace['ynew'], 0.5, axis=1)\n",
    "lowerQuantile = np.quantile(trace['ynew'], 0.025, axis=1)\n",
    "upperQuantile = np.quantile(trace['ynew'], 0.975, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "median = np.quantile(trace['ynew'], 0.5, axis=1)\n",
    "ax.plot(xnew, median, c=\"red\", linewidth=2)\n",
    "\n",
    "lowerQuantile = np.quantile(trace['ynew'], 0.025, axis=1)                              # 95% prediction interval\n",
    "upperQuantile = np.quantile(trace['ynew'], 0.975, axis=1)\n",
    "ax.fill_between(xnew, lowerQuantile, upperQuantile, color=\"lightblue\", alpha=0.2)\n",
    "\n",
    "lowerQuantile = np.quantile(trace['ynew'], 0.25, axis=1)                               #  50% prediction interval    \n",
    "upperQuantile = np.quantile(trace['ynew'], 0.75, axis=1)\n",
    "ax.fill_between(xnew, lowerQuantile, upperQuantile, color=\"lightblue\", alpha=0.6)\n",
    "\n",
    "ax.scatter(np.log10(data['M_STAR']), gasFraction, s=10)\n",
    "\n",
    "ax.set_ylabel(\"Gas fraction\")\n",
    "ax.set_xlabel(r\"$\\log(M/M_{\\odot})$\")\n",
    "ax.set_ylim(-0.1, 1.1)\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling counts with Poisson with PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/GCs.csv\"\n",
    "data = pd.read_csv(url, comment='#')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "ax.scatter(data['MV_T'], data['N_GC'], s=20)\n",
    "ax.set_xlabel(\"Absolute magnitude\")\n",
    "ax.set_ylabel(\"Number of globular clusters\")\n",
    "ax.set_xlim(-11,-25.)\n",
    "ax.set_ylim(-1, 10**5)\n",
    "ax.set_yscale('symlog')\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyMC model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    xobs = pm.Data(\"xobs\", data['MV_T'].values)\n",
    "    yobs = pm.Data(\"yobs\", data['N_GC'].values)\n",
    "    intercept  = pm.Normal('intercept', mu=0, sigma=40)\n",
    "    slope      = pm.Normal('slope', mu=0, sigma=40)\n",
    "    mu         = np.exp(intercept + slope * xobs)\n",
    "    y          = pm.Poisson('y', mu=mu, observed=yobs)\n",
    "\n",
    "    N = len(data['N_GC'].values)\n",
    "    K = 2\n",
    "    dispersion = pm.Deterministic('dispersion', pt.sum((yobs-mu)**2 / mu) / (N-K))\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True, random_seed=3941592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope', 'dispersion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['intercept', 'slope', 'dispersion'], hdi_prob=0.95, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = pm.summary(trace, var_names=['intercept', 'slope'])['mean']\n",
    "meanIntercept = posteriorMean.intercept\n",
    "meanSlope = posteriorMean.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "\n",
    "ax.scatter(data['MV_T'], data['N_GC'], s=20)\n",
    "\n",
    "xvalues = np.linspace(-24, -12, 100)\n",
    "yvalues = np.exp(meanIntercept + meanSlope * xvalues)\n",
    "ax.plot(xvalues, yvalues, c=\"red\", linewidth=3, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"Absolute magnitude\")\n",
    "ax.set_ylabel(\"Number of globular clusters\")\n",
    "ax.set_xlim(-11,-25.)\n",
    "ax.set_ylim(-1.0, 10**5)\n",
    "ax.set_yscale('symlog')\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling counts with Poisson with Stan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same dataset as in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/GCs.csv\"\n",
    "data = pd.read_csv(url, comment='#')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \\\n",
    "\"\"\"\n",
    "data {\n",
    "   int<lower=0> N;                   // Number of data points\n",
    "   int<lower=0> K;                   // Number of model parameters\n",
    "   matrix[N,K] X;                    // Design matrix\n",
    "   int y[N];                         // Globular cluster counts\n",
    "}\n",
    "\n",
    "parameters {\n",
    "   vector[K] theta;                  // Model parameters\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "   real intercept;                   // Separate quantities just to make the trace plots more clear\n",
    "   real slope;\n",
    "  \n",
    "   intercept = theta[1];\n",
    "   slope = theta[2];\n",
    "}\n",
    "\n",
    "model {\n",
    "   y ~ poisson_log(X * theta);       // Poisson with mu = exp(X*theta)\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(np.column_stack([data['MV_T'].values]))                         # Design matrix\n",
    "myData = {'X': X, 'y': data['N_GC'].values, 'N': X.shape[0], 'K': X.shape[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=['intercept', 'slope'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling counts with Negative Binomial with PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/GCs.csv\"\n",
    "data = pd.read_csv(url, comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    \n",
    "    xobs       = pm.Data(\"xobs\", data['MV_T'].values)\n",
    "    yobs       = pm.Data(\"yobs\", data['N_GC'].values)\n",
    "    intercept  = pm.Normal('intercept', mu=0, sigma=40)\n",
    "    slope      = pm.Normal('slope', mu=0, sigma=40)\n",
    "    mu         = np.exp(intercept + slope * xobs)\n",
    "    alpha      = pm.Uniform('alpha', 0, 5)\n",
    "    y          = pm.NegativeBinomial('y', mu=mu, alpha=alpha, observed=yobs)\n",
    "    var        = pm.Deterministic('variance', mu * (1+mu/alpha))\n",
    "\n",
    "    N = len(data['N_GC'].values)\n",
    "    K = 3\n",
    "    dispersion = pm.Deterministic('dispersion', pt.sum((yobs-mu)**2 / var) / (N-K))\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True, random_seed=341592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope', 'alpha', 'dispersion'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is still slightly overdispersed, but we can't exclude that this is caused by the fact that we somewhat misspecified our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMean = pm.summary(trace, var_names=['intercept', 'slope'])['mean']\n",
    "meanIntercept = posteriorMean.intercept\n",
    "meanSlope = posteriorMean.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "\n",
    "ax.scatter(data['MV_T'], data['N_GC'], s=20)\n",
    "\n",
    "xvalues = np.linspace(-24, -12, 100)\n",
    "yvalues = np.exp(meanIntercept + meanSlope * xvalues)\n",
    "ax.plot(xvalues, yvalues, c=\"red\", linewidth=3, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"Absolute magnitude\")\n",
    "ax.set_ylabel(\"Number of globular clusters\")\n",
    "ax.set_xlim(-11,-25.)\n",
    "ax.set_ylim(-1, 10**5)\n",
    "ax.set_yscale('symlog')\n",
    "ax.grid(True, color='gainsboro', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling counts with Negative Binomial with Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JorisDeRidder/DataAnalysisInPhysicsAndAstronomy/main/Datasets/GCs.csv\"\n",
    "data = pd.read_csv(url, comment='#')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \\\n",
    "\"\"\"\n",
    "data {\n",
    "   int<lower=0> N;                   // Number of data points\n",
    "   int<lower=0> K;                   // Number of model parameters\n",
    "   matrix[N,K] X;                    // Design matrix\n",
    "   int y[N];                         // Observed globular cluster counts\n",
    "}\n",
    "\n",
    "parameters {\n",
    "   vector[K] theta;                  // Model coefficients of the straight line\n",
    "   real<lower=1e-3, upper=5> alpha;  // Negative Binomial parameter\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "   real intercept;                   // Separate quantities just to make the trace plots more clear\n",
    "   real slope;\n",
    "  \n",
    "   intercept = theta[1];\n",
    "   slope = theta[2];\n",
    "}\n",
    "\n",
    "model {\n",
    "   y ~ neg_binomial_2_log(X * theta, alpha);       // Negative binomial with mu = exp(X*theta)\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "   real dispersion;\n",
    "   vector[N] mu;\n",
    "   vector[N] variance;\n",
    "   vector[N] PearsonResiduals;\n",
    "   \n",
    "   mu = exp(X * theta);\n",
    "   for (n in 1:N) {\n",
    "      variance[n] = mu[n] * (1 + mu[n]/alpha);\n",
    "      PearsonResiduals[n] = pow(y[n] - mu[n], 2) / variance[n];\n",
    "   }\n",
    "   \n",
    "   dispersion = sum(PearsonResiduals) / (N - K - 1);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lower value of 0 for alpha would lead to infinities, hence I avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(np.column_stack([data['MV_T'].values]))                         # Design matrix\n",
    "myData = {'X': X, 'y': data['N_GC'].values, 'N': X.shape[0], 'K': X.shape[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace, var_names=['intercept', 'slope', 'alpha', 'dispersion'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A zero-truncated Poisson model with Stan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an artificial dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sp.stats.poisson.rvs(mu=2.5, size=200)\n",
    "y = y + 1                                                     # No zeros in our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = {'N': len(y), 'y': y}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan script: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \\\n",
    "\"\"\"\n",
    "data {\n",
    "   int N;\n",
    "   int<lower=1> y[N];                                   // Our observed counts dataset\n",
    "}\n",
    "\n",
    "parameters {\n",
    "   real<lower=0> lambda;\n",
    "}\n",
    "\n",
    "model {\n",
    "\n",
    "   lambda ~ cauchy(0,5);                                // Half-cauchy prior\n",
    "\n",
    "   for (n in 1:N) {\n",
    "      y[n] ~ poisson(lambda)  T[1,];                    // Truncator flag T[low, high]\n",
    "   }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stan.build(code, data=myData, random_seed=1325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = model.sample(num_chains=4, num_samples=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A zero-truncated Poisson model with PyMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an artificial dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sp.stats.poisson.rvs(mu=2.5, size=200)\n",
    "y = y + 1                                                     # No zeros in our dataset (average is now around 3.5 rather than 2.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model count data that have no zero counts among them, we can use a truncated Poisson model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as myModel:\n",
    "    \n",
    "    yobs = pm.ConstantData(\"yobs\", y)                                                                          # The observations\n",
    "\n",
    "    mu = pm.HalfNormal(\"mu\", sigma=4)                                                                          # The prior on the average number of counts\n",
    "    truncatedPoisson = pm.Truncated(\"truncated_poisson\", pm.Poisson.dist(mu=mu), lower=1, observed=yobs)       # Truncate the counts to be >= 1.\n",
    "\n",
    "    trace = pm.sample(3000, chains=4, cores=2, return_inferencedata=True, random_seed=341592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_trace(trace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [contents](#Contents)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "70e2515f7afd97f80b58b2d9ab25af8b5ba10c164f3f9636d94ad1d1ce740eec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
